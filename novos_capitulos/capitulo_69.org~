* Capítulo 69: Intrinsics e otimizações manuais

A auto-vetorização é uma ferramenta poderosa, mas tem seus limites. O compilador, por mais inteligente que seja, é conservador. Ele precisa provar que uma transformação é segura antes de aplicá-la. Há momentos em que o programador possui um conhecimento de domínio sobre o algoritmo ou os dados que o compilador não tem, ou quando o padrão de acesso à memória é muito complexo para a análise estática do compilador.

Nesses cenários, para extrair o último pingo de desempenho, abandonamos a esperança da automação e pegamos as rédeas nós mesmos. Fazemos isso usando intrinsics.

** 69.1 O Que São Intrinsics?

Um intrinsic é uma função especial, cujo nome geralmente começa com _mm_ (para SSE/AVX) ou v (para NEON), que o compilador mapeia diretamente para uma única instrução de assembly SIMD. Eles são a ponte entre o código C++ e o conjunto de instruções vetoriais do hardware.

Usar intrinsics é como escrever em assembly, mas com a conveniência da sintaxe de função do C++ e o gerenciamento de registradores do compilador. Você opera em tipos de dados especiais que representam os registradores SIMD:

    __m128: Um registrador de 128 bits contendo quatro floats.
    __m128i: Um registrador de 128 bits contendo dados inteiros (2x 64-bit, 4x 32-bit, etc.).
    __m256: Um registrador de 256 bits contendo oito floats.
    __m256i: Um registrador de 256 bits contendo dados inteiros.

O código se parece com isto:

#+begin_src cpp
#include <immintrin.h> // Cabeçalho principal para intrinsics AVX/SSE

// Função que soma dois arrays de floats usando intrinsics AVX
void add_arrays_avx(float* a, float* b, int n) {
    // Processa os dados em blocos de 8 floats (256 bits)
    for (int i = 0; i <= n - 8; i += 8) {
        // 1. Carrega 8 floats de 'a' para um registrador YMM
        __m256 vec_a = _mm256_loadu_ps(&a[i]);
        // 2. Carrega 8 floats de 'b' para outro registrador YMM
        __m256 vec_b = _mm256_loadu_ps(&b[i]);
        
        // 3. Soma os dois registradores (8 floats de uma vez)
        __m256 vec_sum = _mm256_add_ps(vec_a, vec_b);
        
        // 4. Armazena os 8 resultados de volta em 'a'
        _mm256_storeu_ps(&a[i], vec_sum);
    }
    
    // Lida com o resto dos elementos que não formam um bloco de 8
    for (int i = n - (n % 8); i < n; ++i) {
        a[i] += b[i];
    }
}
#+end_src

Este código é explícito. Não há adivinhação. Estamos dizendo ao compilador exatamente quais instruções SIMD usar.

** 69.2 O Dicionário SIMD: Operações Fundamentais

Para ser eficaz com intrinsics, você precisa conhecer o vocabulário básico. A Intel Intrinsics Guide é a referência indispensável aqui. As operações mais comuns são:

    * *Load/Store*: Carregar dados da memória para um registrador e armazenar de volta.
        _mm256_load_ps(ptr): Carrega 8 floats de um endereço alinhado. Falhará se o ponteiro não for alinhado a 32 bytes.
        _mm256_loadu_ps(ptr): Carrega 8 floats de um endereço desalinhado ("unaligned"). Mais lento que a versão alinhada, mas mais flexível.
        _mm256_store_ps(ptr, vec) / _mm256_storeu_ps(ptr, vec): As operações de armazenamento correspondentes.
        _mm256_setzero_ps(): Retorna um vetor de zeros.
        _mm256_set1_ps(val): Retorna um vetor onde todas as 8 posições são preenchidas com val (conhecido como "broadcast").

    * *Aritmética*:
        _mm256_add_ps(a, b): Adição.
        _mm256_sub_ps(a, b): Subtração.
        _mm256_mul_ps(a, b): Multiplicação.
        _mm256_div_ps(a, b): Divisão.
        _mm256_sqrt_ps(a): Raiz quadrada.

    * *Lógica e Comparação-*:
        _mm256_and_ps(a, b), _mm256_or_ps(a, b), _mm256_xor_ps(a, b): Operações lógicas bit a bit.
        _mm256_cmp_ps(a, b, predicate): Compara os 8 floats em a e b com base em um predicado (ex: _CMP_LT_OQ para "menor que"). Retorna um vetor de máscara onde cada elemento é todo 1s (se verdadeiro) ou todo 0s (se falso).

    * *Manipulação de Dados (Shuffling/Permuting)*:
    Estas são as operações mais complexas e poderosas. Elas permitem reordenar os elementos dentro de um vetor ou combinar elementos de dois vetores diferentes. São essenciais para algoritmos como transposição de matrizes ou conversões de layout de dados (AoS para SoA em tempo de execução). _mm256_shuffle_ps, _mm256_permute_ps, _mm256_blend_ps são exemplos.

69.3 Quando Usar Intrinsics?

A decisão de usar intrinsics não deve ser tomada de ânimo leve. O código se torna mais complexo, menos legível e atrelado a uma arquitetura específica (embora seja possível usar #ifdef para fornecer implementações diferentes para AVX, SSE, NEON, etc.).

Use intrinsics quando:

    O Auto-vetorizador Falha: Você analisou a saída do compilador (-fopt-info-vec) e ele confirma que não consegue vetorizar um loop crítico, mas você sabe que a vetorização é possível.
    Padrões de Acesso à Memória Complexos: O algoritmo requer acessos não contíguos, como em uma busca em uma tabela hash ou ao seguir índices. O auto-vetorizador raramente lida bem com isso, mas você pode usar instruções "gather" (_mm256_i32gather_ps) para carregar dados de múltiplos endereços de memória em um único vetor.
    Controle de Precisão e Algoritmos Específicos: Você precisa usar aproximações de baixa precisão, mas rápidas, para funções como reciprocal (_mm256_rcp_ps) ou rsqrt (_mm256_rsqrt_ps), que são comuns em gráficos 3D.
    Otimização de Algoritmos Conhecidos: Para algoritmos padrão como redução (soma de todos os elementos de um array), produto escalar ou multiplicação de matrizes, existem "receitas" de SIMD bem estabelecidas que superam o código auto-vetorizado.

Exemplo: Redução (Soma Horizontal)
Somar todos os elementos de um vetor SIMD é um desafio, pois as operações aritméticas são verticais. A solução envolve uma série de shuffles e adições para somar os elementos horizontalmente.

cpp

Copy
float horizontal_add(__m256 vec) {
    // vec = [v7, v6, v5, v4, v3, v2, v1, v0]
    __m128 hi_half = _mm256_extractf128_ps(vec, 1); // [v7, v6, v5, v4]
    __m128 lo_half = _mm256_castps256_ps128(vec);   // [v3, v2, v1, v0]
    __m128 sum_128 = _mm_add_ps(lo_half, hi_half);  // [v7+v3, v6+v2, v5+v1, v4+v0]
    
    // Agora, some horizontalmente o vetor de 128 bits (técnica padrão)
    sum_128 = _mm_hadd_ps(sum_128, sum_128);
    sum_128 = _mm_hadd_ps(sum_128, sum_128);
    
    return _mm_cvtss_f32(sum_128); // Extrai o float escalar final
}

Este é o tipo de lógica que um compilador pode ter dificuldade em gerar, mas que pode ser escrita manualmente para obter o desempenho máximo.
69.4 Wrappers de SIMD

Escrever código com intrinsics puros pode ser verboso e propenso a erros. Uma abordagem popular é criar uma fina camada de abstração em C++ sobre os intrinsics. Isso envolve a criação de uma classe Vector8f, por exemplo, que encapsula um __m256 e sobrecarrega os operadores aritméticos (+, -, *, /).

cpp

Copy
struct Vector8f {
    __m256 data;
    Vector8f(float val) : data(_mm256_set1_ps(val)) {}
    // ... outros construtores ...
};

inline Vector8f operator+(const Vector8f& a, const Vector8f& b) {
    Vector8f result;
    result.data = _mm256_add_ps(a.data, b.data);
    return result;
}

Isso permite escrever código que se parece muito com código escalar (result = a + b;), mas que gera as instruções SIMD desejadas. Bibliotecas como Agner Fog's VCL (Vector Class Library) ou a std::experimental::simd (que está a caminho da padronização) formalizam essa abordagem.

Conclusão

Os intrinsics são a ferramenta de escape do programador de alto desempenho. Eles nos permitem ir além das capacidades do auto-vetorizador e ditar o código exato que a máquina deve executar. É um mundo de complexidade, onde o programador deve pensar em termos de registradores, alinhamento e latência de instruções. O custo é a portabilidade e a legibilidade, mas a recompensa, nos loops de código mais críticos, é o desempenho máximo que o silício é capaz de oferecer. Usar intrinsics é o ato final de assumir a responsabilidade pela performance, alinhando o software com o hardware no nível mais íntimo possível.

Leituras de Referência:

    Intel Intrinsics Guide: Essencial. Use-a como um dicionário interativo.
    Agner Fog - "Optimizing Software in C++": O Capítulo 13, "Explicit vector coding with intrinsics", é um guia prático para começar.
    "Introduction to C++ SIMD Intrinsics" (vários tutoriais online): Há muitos recursos excelentes que fornecem exemplos passo a passo para tarefas comuns de SIMD.
